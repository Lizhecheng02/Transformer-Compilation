{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMLpD2e8wbSZILcRskVkSJG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TliO2imLOBiR"},"outputs":[],"source":["!pip install datasets trl peft bitsandbytes wandb accelerate transformers"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"id":"Di2OyE13OFy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import gc\n","import torch\n","import transformers\n","import bitsandbytes as bnb\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    BitsAndBytesConfig\n",")\n","from datasets import load_dataset\n","from peft import (\n","    LoraConfig,\n","    PeftModel,\n","    get_peft_model,\n","    prepare_model_for_kbit_training\n",")\n","from trl import DPOTrainer, setup_chat_format"],"metadata":{"id":"9WlztevLOHXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","new_model = \"DPOLlama-3-8B\""],"metadata":{"id":"nfbUXc3SOML0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_use_double_quant=True\n",")"],"metadata":{"id":"uemEMCilOQPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(base_model)\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    torch_dtype=torch.bfloat16,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")"],"metadata":{"id":"HAZxRJoMOSNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ref_model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    torch_dtype=torch.bfloat16,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")"],"metadata":{"id":"BvPHfXfZOVYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["peft_config = LoraConfig(\n","    r=16,\n","    lora_alpha=16,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj']\n",")"],"metadata":{"id":"hotIJD_wOXmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = load_dataset(\"Intel/orca_dpo_pairs\")['train']"],"metadata":{"id":"HhOH-oQROaeZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.shuffle(seed=42).select(range(1000))"],"metadata":{"id":"Ts9kDEcMOcKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"pSlSpa0pOdo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[19]['question']"],"metadata":{"id":"bA24B60nOfBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[19]['rejected']"],"metadata":{"id":"gf2WY_MzOjon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[19]['chosen']"],"metadata":{"id":"kbgEeVqSOlGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -L https://raw.githubusercontent.com/chujiezheng/chat_templates/main/chat_templates/llama-3-chat.jinja"],"metadata":{"id":"o3DFH7E4Omfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_template = open('llama-3-chat.jinja').read()\n","chat_template = chat_template.replace('    ', '').replace('\\n', '')\n","tokenizer.chat_template = chat_template"],"metadata":{"id":"wg1qJQ9tOoj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_format(example):\n","    # Format system\n","    if len(example['system']) > 0:\n","        message = {\"role\": \"system\", \"content\": example['system']}\n","        system = tokenizer.apply_chat_template([message], tokenize=False)\n","    else:\n","        system = \"\"\n","    # Format instruction\n","    message = {\"role\": \"user\", \"content\": example['question']}\n","    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n","    # Format chosen answer\n","    chosen = example['chosen'] + \"<|eot_id|>\\n\"\n","    # Format rejected answer\n","    rejected = example['rejected'] + \"<|eot_id|>\\n\"\n","    return {\n","        \"prompt\": system + prompt,\n","        \"chosen\": chosen,\n","        \"rejected\": rejected,\n","    }"],"metadata":{"id":"YFjZxVzbOq_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_columns = dataset.column_names\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\"\n","\n","dataset = dataset.map(\n","    dataset_format,\n","    remove_columns=original_columns,\n","    num_proc= os.cpu_count()\n",")"],"metadata":{"id":"Q-lL3zOPOvkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[19]"],"metadata":{"id":"_v68nanJOxYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","\n","wandb.login()"],"metadata":{"id":"ESjH4B6yOzU2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    max_steps=200,\n","    save_strategy=\"no\",\n","    logging_steps=1,\n","    output_dir=new_model,\n","    optim=\"paged_adamw_32bit\",\n","    warmup_steps=100,\n","    bf16=True,\n","    report_to=\"wandb\"\n",")"],"metadata":{"id":"haBpFlnkO0x6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer = DPOTrainer(\n","    model,\n","    ref_model,\n","    args=training_args,\n","    train_dataset=dataset,\n","    tokenizer=tokenizer,\n","    peft_config=peft_config,\n","    beta=0.1,\n","    max_prompt_length=512,\n","    max_length=1024,\n","    force_use_ref_model=True\n",")"],"metadata":{"id":"tXcu8dVoO3Md"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"-cgi4oA8O5c0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer.train()"],"metadata":{"id":"jBOsWHEcO64I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpo_trainer.model.save_pretrained(\"final_ckpt\")"],"metadata":{"id":"akcWR_7SO_pG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(\"final_ckpt\")"],"metadata":{"id":"Xy-zheH5PAIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del dpo_trainer, model, ref_model\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"LPDqKu55PBrs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n","    return_dict=True,\n","    torch_dtype=torch.float16\n",")"],"metadata":{"id":"wxhT7RUbPDRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n","tokenizer.chat_template = chat_template"],"metadata":{"id":"9R7S1hFaPE14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = PeftModel.from_pretrained(base_model, \"final_ckpt\")\n","model = model.merge_and_unload()\n","\n","# Save model and tokenizer\n","model.save_pretrained(new_model)\n","tokenizer.save_pretrained(new_model)"],"metadata":{"id":"8Znyh8y1PHgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline = transformers.pipeline(\n","    \"text-generation\",\n","    model=new_model,\n","    tokenizer=tokenizer\n",")"],"metadata":{"id":"lTrlQhpEPK_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["message = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant chatbot that provides concise answers.\"},\n","    {\"role\": \"user\", \"content\": \"What are GPUs and why would I use them for machine learning tasks?\"}\n","]\n","tokenizer = AutoTokenizer.from_pretrained(new_model)\n","prompt = tokenizer.apply_chat_template(message, add_generation_prompt=True, tokenize=False)"],"metadata":{"id":"-vbSGDWTPMvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequences = pipeline(\n","    prompt,\n","    do_sample=True,\n","    temperature=0.7,\n","    top_p=0.9,\n","    num_return_sequences=1,\n","    max_length=200\n",")\n","print(sequences[0]['generated_text'])"],"metadata":{"id":"FLed3VeuPQGu"},"execution_count":null,"outputs":[]}]}