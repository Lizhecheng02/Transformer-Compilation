{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP8DbyhACr5PY/0CRWp6z3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"02ad7c9579dd42f6b93f369fd028060c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5bff0c4cfd6471090f82f0103306ae0","IPY_MODEL_6a9984dbfa0b48b1b13e5f33c26fd124","IPY_MODEL_3a42962ec7a1469bbfcf361261177d4c"],"layout":"IPY_MODEL_d158011901224449bc09c24ef937e3f1"}},"a5bff0c4cfd6471090f82f0103306ae0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df2c03a4b1674fc5b90a7408fac41fb6","placeholder":"​","style":"IPY_MODEL_6be457be26f7470db9c64a4555744386","value":"Map: 100%"}},"6a9984dbfa0b48b1b13e5f33c26fd124":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2400e4eb15874a379cb104bbcf3ba8e8","max":33887,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8738d44e2c66401698a38002d8a00f13","value":33887}},"3a42962ec7a1469bbfcf361261177d4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3784c0cd9114ee58e41d6726ff1cb15","placeholder":"​","style":"IPY_MODEL_3420de36ac2141d89cc05c1024331656","value":" 33887/33887 [00:12&lt;00:00, 3595.68 examples/s]"}},"d158011901224449bc09c24ef937e3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df2c03a4b1674fc5b90a7408fac41fb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be457be26f7470db9c64a4555744386":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2400e4eb15874a379cb104bbcf3ba8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8738d44e2c66401698a38002d8a00f13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3784c0cd9114ee58e41d6726ff1cb15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3420de36ac2141d89cc05c1024331656":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install datasets peft trl bitsandbytes accelerate -q"],"metadata":{"id":"wMKbjc02D357","executionInfo":{"status":"ok","timestamp":1714792868059,"user_tz":420,"elapsed":11727,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"-HEuTEfLDuDB","executionInfo":{"status":"ok","timestamp":1714793963964,"user_tz":420,"elapsed":4,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"outputs":[],"source":["import torch\n","from datasets import load_dataset, Dataset\n","from peft import LoraConfig, PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n","from trl import SFTTrainer\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","source":["dataset_id=\"burkelibbey/colors\"\n","base_model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""],"metadata":{"id":"Qjmkoxx3D8WW","executionInfo":{"status":"ok","timestamp":1714792883306,"user_tz":420,"elapsed":13,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# def formatted_train(question, answer):\n","#     return f\"<|user|>\\n{question}</s>\\n<|assistant|>\\n{answer}</s>\""],"metadata":{"id":"DiurC7JwE07d","executionInfo":{"status":"ok","timestamp":1714792883306,"user_tz":420,"elapsed":12,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def prepare_train_data(data_id):\n","    data = load_dataset(data_id, split=\"train\")\n","    data_df = data.to_pandas()\n","    data_df[\"text\"] = data_df[[\"description\", \"color\"]].apply(lambda x: \"<|system|>\\n\" + \"You are a helpful assisant that give me back the Hex Color Code of the color I describe.\" + \"</s>\\n<|user|>\\n\" + x[\"description\"] + \"</s>\\n<|assistant|>\\n\" + x[\"color\"] + \"</s>\", axis=1)\n","    data = Dataset.from_pandas(data_df)\n","    print(data)\n","    return data"],"metadata":{"id":"iIMx8tuoE5_o","executionInfo":{"status":"ok","timestamp":1714792883306,"user_tz":420,"elapsed":12,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_model_and_tokenizer(mode_id):\n","    tokenizer = AutoTokenizer.from_pretrained(mode_id)\n","    tokenizer.pad_token = tokenizer.eos_token\n","    bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=\"float16\",\n","        bnb_4bit_use_double_quant=True\n","    )\n","    model = AutoModelForCausalLM.from_pretrained(\n","        mode_id,\n","        quantization_config=bnb_config,\n","        device_map=\"auto\"\n","    )\n","    model.config.use_cache=False\n","    model.config.pretraining_tp=1\n","    return model, tokenizer"],"metadata":{"id":"5sho2jgRE-Ud","executionInfo":{"status":"ok","timestamp":1714792883306,"user_tz":420,"elapsed":12,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = get_model_and_tokenizer(base_model_id)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pnNDhg2FQhM","executionInfo":{"status":"ok","timestamp":1714792890426,"user_tz":420,"elapsed":7131,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"567ad0d1-a9ad-4e1c-ab49-bb40fbb7ca89"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(32000, 2048)\n","    (layers): ModuleList(\n","      (0-21): 22 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n","          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n","          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n","          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n","          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm()\n","        (post_attention_layernorm): LlamaRMSNorm()\n","      )\n","    )\n","    (norm): LlamaRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful assisant that give me back the Hex Color Code of the color I describe.\",\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Strong blue: This is a dark, rich shade of blue that carries a strong resonance, similar to the deep blue of a clear evening sky.\"\n","    }\n","]\n","prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n","print(outputs[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4B6VjgrgLu2","executionInfo":{"status":"ok","timestamp":1714792900806,"user_tz":420,"elapsed":10389,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"7b5bc0f8-c337-4b36-a771-0e2f13b73185"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<|system|>\n","You are a helpful assisant that give me back the Hex Color Code of the color I describe.</s>\n","<|user|>\n","Strong blue: This is a dark, rich shade of blue that carries a strong resonance, similar to the deep blue of a clear evening sky.</s>\n","<|assistant|>\n","Strong blue is a hex color code of #0000cc. This color has a deep, rich blue hue that carries a strong resonance, similar to the deep blue of a clear evening sky. The color code #0000cc is a combination of red, green, and blue colors that create a deep, rich color.\n"]}]},{"cell_type":"code","source":["def finetune_tinyllama(data_id, base_model_id):\n","    data = prepare_train_data(data_id)\n","    model, tokenizer = get_model_and_tokenizer(base_model_id)\n","\n","    peft_config = LoraConfig(\n","        r=16,\n","        lora_alpha=64,\n","        lora_dropout=0.05,\n","        bias=\"none\",\n","        task_type=\"CAUSAL_LM\",\n","        target_modules=[\"q_proj\", \"k_proj\", \"o_proj\", \"gate_proj\"]\n","    )\n","    training_arguments = TrainingArguments(\n","        output_dir=\"output\",\n","        per_device_train_batch_size=4,\n","        gradient_accumulation_steps=4,\n","        optim=\"paged_adamw_8bit\",\n","        learning_rate=2e-4,\n","        lr_scheduler_type=\"cosine\",\n","        save_strategy=\"steps\",\n","        save_steps=100,\n","        logging_steps=10,\n","        num_train_epochs=3,\n","        max_steps=500,\n","        save_total_limit=5,\n","        fp16=True\n","    )\n","    trainer = SFTTrainer(\n","        model=model,\n","        train_dataset=data,\n","        peft_config=peft_config,\n","        dataset_text_field=\"text\",\n","        args=training_arguments,\n","        tokenizer=tokenizer,\n","        packing=False,\n","        max_seq_length=512\n","    )\n","    trainer.train()"],"metadata":{"id":"dgxpGcIGFCnD","executionInfo":{"status":"ok","timestamp":1714792900807,"user_tz":420,"elapsed":11,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    finetune_tinyllama(dataset_id, base_model_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["02ad7c9579dd42f6b93f369fd028060c","a5bff0c4cfd6471090f82f0103306ae0","6a9984dbfa0b48b1b13e5f33c26fd124","3a42962ec7a1469bbfcf361261177d4c","d158011901224449bc09c24ef937e3f1","df2c03a4b1674fc5b90a7408fac41fb6","6be457be26f7470db9c64a4555744386","2400e4eb15874a379cb104bbcf3ba8e8","8738d44e2c66401698a38002d8a00f13","f3784c0cd9114ee58e41d6726ff1cb15","3420de36ac2141d89cc05c1024331656"]},"id":"oBD_uuU9FSfk","executionInfo":{"status":"ok","timestamp":1714793594854,"user_tz":420,"elapsed":694058,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"6696b4fe-31b3-40ed-9376-d3ea5c69c757"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['color', 'description', 'text'],\n","    num_rows: 33887\n","})\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/33887 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ad7c9579dd42f6b93f369fd028060c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 11:08, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.556200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.892900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.823000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.811600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.788900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.764600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.788300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.755700</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.753900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.736100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.765900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.763600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.746100</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.740700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.719400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.748100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.739900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.728900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.734200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.720500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.724200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.717800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.729700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.721500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.694300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.701300</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.718000</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.713500</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.683100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.698600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.670200</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.727100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.703100</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.668600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.674100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.728600</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.689200</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.687100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.705300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.666500</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.696200</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.680300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.725700</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.701400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.712000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.687700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.705100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.680900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.682400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.704100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["adapter_id = \"/content/output/checkpoint-500\""],"metadata":{"id":"odx4TP9eiOAO","executionInfo":{"status":"ok","timestamp":1714793595074,"user_tz":420,"elapsed":223,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["peft_model = PeftModel.from_pretrained(model, adapter_id)\n","pipe = pipeline(\"text-generation\", model=peft_model, tokenizer=tokenizer)\n","\n","messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful assisant that give me back the Hex Color Code of the color I describe.\",\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Strong blue: This is a dark, rich shade of blue that carries a strong resonance, similar to the deep blue of a clear evening sky.\"\n","    }\n","]\n","prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.1, top_k=50, top_p=0.95, eos_token_id=tokenizer.encode(\"\\n\"))\n","print(outputs[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07t-lNDQitZR","executionInfo":{"status":"ok","timestamp":1714794037128,"user_tz":420,"elapsed":2636,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"4653bda9-1368-46a4-c2cf-672497d2b1c3"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"]},{"output_type":"stream","name":"stdout","text":["<|system|>\n","You are a helpful assisant that give me back the Hex Color Code of the color I describe.</s>\n","<|user|>\n","Strong blue: This is a dark, rich shade of blue that carries a strong resonance, similar to the deep blue of a clear evening sky.</s>\n","<|assistant|>\n","#1120e0\n","\n"]}]}]}