{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOeGa9XObGqTr2hXR+5Pigd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"An8EgE9YFTq6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298423544,"user_tz":420,"elapsed":39035,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"722d4e9e-1ef7-4a26-d4bc-532758692cdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-as92r_rn/unsloth_f1cd0ece43994f3289fea25ea0d15971\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-as92r_rn/unsloth_f1cd0ece43994f3289fea25ea0d15971\n","  Resolved https://github.com/unslothai/unsloth.git to commit 4211cc01409e3ced4f7abebaf68e244193b46e2c\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.3)\n","Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.40.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: xformers<0.0.26 in /usr/local/lib/python3.10/dist-packages (0.0.25.post1)\n","Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.6)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n"]}],"source":["!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes"]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from transformers import TrainingArguments, TextStreamer\n","import torch"],"metadata":{"id":"zPuQ4YohFdyV","executionInfo":{"status":"ok","timestamp":1715298436705,"user_tz":420,"elapsed":13163,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["max_seq_length = 512 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=\"unsloth/Phi-3-mini-4k-instruct\",\n","    max_seq_length=max_seq_length,\n","    dtype=dtype,\n","    load_in_4bit=load_in_4bit\n",")"],"metadata":{"id":"SThyGfCiFpCJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298445804,"user_tz":420,"elapsed":9110,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"5e0f2bb7-abb1-4178-eec4-6bae1236f704"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You passed in `unsloth/Phi-3-mini-4k-instruct` and `load_in_4bit = True`.\n","We shall load `unsloth/Phi-3-mini-4k-instruct-bnb-4bit` for 4x faster loading.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Fast Mistral patching release 2024.4\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"stream","name":"stderr","text":["Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"]}]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules=[\n","        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","        \"gate_proj\", \"up_proj\", \"down_proj\"\n","    ],\n","    lora_alpha=16,\n","    lora_dropout=0, # Supports any, but = 0 is optimized\n","    bias=\"none\",  # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing=\"unsloth\", # True or \"unsloth\" for very long context\n","    random_state=3407,\n","    use_rslora=False,  # We support rank stabilized LoRA\n","    loftq_config=None # And LoftQ\n",")"],"metadata":{"id":"mqKyUHdNF2z1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298450629,"user_tz":420,"elapsed":4834,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"1d213e31-ad7a-440d-e28e-615512e8f612"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"<|user|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","### Question:\n","{}\n","### Response:\n","{}<|end|>\n","\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token\n","print(EOS_TOKEN)\n","def formatting_prompts_func(examples):\n","    inputs = examples[\"question\"]\n","    outputs = examples[\"answer\"]\n","    texts = []\n","    for input, output in zip(inputs, outputs):\n","        text = alpaca_prompt.format(input, output)\n","        texts.append(text)\n","    return {\"text\": texts}\n","\n","dataset = load_dataset(\"microsoft/orca-math-word-problems-200k\", split=\"train[:1%]\")\n","dataset = dataset.map(formatting_prompts_func, batched=True)"],"metadata":{"id":"BHaoKe9pGGC-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298452882,"user_tz":420,"elapsed":2262,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"db86d178-7d23-4e84-9188-1844bd97c8ca"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>\n"]}]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer([\n","    alpaca_prompt.format(\n","        \"What is the answer of 241 - (-241) + 1?\", # input\n","        \"\", # output - leave this blank for generation!\n","    )],\n","    return_tensors=\"pt\"\n",").to(\"cuda\")\n","\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256)"],"metadata":{"id":"mafT8_JNIJEP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298479660,"user_tz":420,"elapsed":26787,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"edc21973-7c7e-43d7-f561-ec3b5319f593"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>  <|user|> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","### Question:\n","What is the answer of 241 - (-241) + 1?\n","### Response:\n"," <|end|> <|assistant|> The answer is 644.\n","\n","Here's the step-by-step calculation:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + 241, which equals 482.\n","2. Then, add 1 to the result: 482 + 1 equals 643.\n","\n","However, there seems to be a mistake in the calculation. The correct calculation should be:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + 241, which equals 482.\n","2. Then, add 1 to the result: 482 + 1 equals 483.\n","\n","So, the correct answer is 483. <|end|> <|assistant|> The correct calculation is as follows:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + \n"]}]},{"cell_type":"code","source":["trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=dataset,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args = TrainingArguments(\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=8,\n","        num_train_epochs=1,\n","        warmup_steps=10,\n","        max_steps=100,\n","        learning_rate=2e-4,\n","        fp16=not torch.cuda.is_bf16_supported(),\n","        bf16=torch.cuda.is_bf16_supported(),\n","        logging_steps=10,\n","        optim=\"adamw_8bit\",\n","        weight_decay=0.01,\n","        lr_scheduler_type=\"cosine\",\n","        seed=3407,\n","        output_dir=\"outputs\"\n","    )\n",")"],"metadata":{"id":"I0yKQW2mGhXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298479661,"user_tz":420,"elapsed":6,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"4170c7b8-1570-4192-d159-b14838966b27"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","source":["gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"id":"cRoF9QeDIEUl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715298479661,"user_tz":420,"elapsed":4,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"a6a2c153-5d2b-42a9-bca6-29ac34fa5cd1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","2.992 GB of memory reserved.\n"]}]},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"id":"RCBUpDUOKCM3","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"status":"ok","timestamp":1715299211071,"user_tz":420,"elapsed":731189,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"4b05eba9-baa2-406e-ecf6-10a14d7f98e1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 2,000 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 8\n","\\        /    Total batch size = 16 | Total steps = 100\n"," \"-____-\"     Number of trainable parameters = 119,537,664\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [100/100 12:02, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.293700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.500700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.430200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.315800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.326600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.398700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.328900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.317500</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.373200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.258400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer([\n","    alpaca_prompt.format(\n","        \"What is the answer of 241 - (-241) + 1?\", # input\n","        \"\", # output - leave this blank for generation!\n","    )],\n","    return_tensors=\"pt\"\n",").to(\"cuda\")\n","\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256)"],"metadata":{"id":"JB__I1JyKF8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715299228464,"user_tz":420,"elapsed":17403,"user":{"displayName":"Zhecheng Li","userId":"14410450994449980422"}},"outputId":"bceaf7bb-8c29-4ea2-e4b5-e524ea435c14"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>  <|user|> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","### Question:\n","What is the answer of 241 - (-241) + 1?\n","### Response:\n"," <|end|> <|assistant|> The answer is 644.\n","\n","Here's the step-by-step calculation:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + 241, which equals 482.\n","2. Then, add 1 to the result: 482 + 1 equals 643.\n","\n","However, there seems to be a mistake in the calculation. The correct calculation should be:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + 241, which equals 482.\n","2. Then, add 1 to the result: 482 + 1 equals 483.\n","\n","So, the correct answer is 483. <|end|> <|assistant|> The correct calculation is as follows:\n","\n","1. Subtracting a negative number is the same as adding its positive counterpart. So, 241 - (-241) becomes 241 + \n"]}]}]}